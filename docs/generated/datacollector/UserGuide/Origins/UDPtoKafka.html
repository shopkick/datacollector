
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="description" content="The UDP to Kafka origin reads messages from one or more UDP ports and writes each message directly to Kafka. However, the UDP to Kafka origin is now deprecated and will be removed in a future release. ..." /><meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="UDP to Kafka (Deprecated)" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/Origins_title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_jzq_jcz_pw" /><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/css/commonltr.css?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></link><title>UDP to Kafka (Deprecated)</title><!--  Generated with Oxygen version @@WEBHELP_VERSION@@, build number @@WEBHELP_BUILD_NUMBER@@.  --><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/css/webhelp_topic.css?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></link><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/skins/skin.css?buildId=@@WEBHELP_BUILD_NUMBER@@" /><script type="text/javascript"><!--
          
          var prefix = "../../../index.html";
          
          --></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery-3.1.1.min.js"><!----></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../../../oxygen-webhelp/resources/js/log.js?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></script><script type="text/javascript" charset="utf-8" src="../../../oxygen-webhelp/resources/js/webhelp_topic.js?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></script>
  <!--
  Copyright 2018 StreamSets Inc.
  
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
  <script type="text/javascript">
    <!--
    var parentWindow = window.name;
    console.log("1. " + parentWindow);
    if (!(parentWindow == "frm" || parentWindow == "contentwin")) {
        var currHash = window.location.hash.substr(1);
        console.log("2. " + currHash);
        console.log("3. " + currHash.indexOf("datacollector/UserGuide/"));

        if ( currHash.indexOf("datacollector/UserGuide/") == -1 ) {
            window.location.hash = "#datacollector/UserGuide/" + currHash;
        }
    }
-->
  </script>
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../../../datacollector/UserGuide/Origins/Origins_title.html" title="Origins">Origins</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../../../datacollector/UserGuide/Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_jzq_jcz_pw">
 <h1 class="title topictitle1">UDP to Kafka (Deprecated)</h1>

 <div class="body conbody">
        <p class="p">The UDP to Kafka origin reads messages from one
            or more UDP ports and writes each message directly to Kafka. However, the UDP to Kafka
            origin is now deprecated and will be removed in a future release. We recommend using the
                <a class="xref" href="UDPMulti.html#concept_wng_g5f_5bb">UDP Multithreaded Source
                origin</a> that can use multiple threads to enable parallel processing of data
            from multiple UDP ports.</p>

        <p class="p">Use the UDP to Kafka origin to read large volumes of data from multiple UDP ports and
            write the data immediately to Kafka, without additional processing.</p>

        <p class="p">Here is an example of the recommended architecture for using the UDP to Kafka origin:</p>

        <p class="p"><img class="image" id="concept_jzq_jcz_pw__image_jkp_jhn_vw" src="../Graphics/UDPtoKafka-arch.png" height="165" width="354" /></p>

        <p class="p">If you need to process data before writing it to Kafka, need to write to a destination
            system other than Kafka, or if the origin does not need to process high volumes of data,
            use the UDP Source origin.</p>

        <div class="p">UDP to Kafka <span class="ph">can process <a class="xref" href="https://collectd.org/" target="_blank">collectd</a> messages, <span class="ph" id="concept_jzq_jcz_pw__d47352e2531">NetFlow 5 and NetFlow 9 messages</span>, and the
                        following types of syslog messages:</span><ul class="ul" id="concept_jzq_jcz_pw__ul_zwj_rm4_4x">
                        <li class="li">RFC 5424 (<a class="xref" href="https://tools.ietf.org/html/rfc5424" target="_blank">https://tools.ietf.org/html/rfc5424</a>)</li>

                        <li class="li">RFC 3164 (<a class="xref" href="https://tools.ietf.org/html/rfc3164" target="_blank">https://tools.ietf.org/html/rfc3164</a>)</li>

                        <li class="li">Non-standard common messages, such as RFC 3339 dates with no version
                              digit</li>

                  </ul>
</div>

     <p class="p"><span class="ph">When processing NetFlow messages, the stage generates
                        different records based on the NetFlow version. When processing NetFlow 9,
                        the records are generated based on the NetFlow 9 configuration properties.
                        For more information, see <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_thl_nnr_hbb">NetFlow Data Processing</a>.</span></p>

        <p class="p">When you configure UDP to Kafka, you specify the UDP ports to use, Kafka configuration
            information, and advanced properties such as the maximum number of write requests.</p>

        <p class="p">You can add Kafka configuration properties and enable Kafka security as needed. </p>

    </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_flq_twg_qw">
 <h2 class="title topictitle2">Pipeline Configuration</h2>

 
 <div class="body conbody"><p class="shortdesc">When you use a UDP to Kafka origin in a pipeline, connect the origin to a Trash
        destination. </p>

        <p class="p">The UDP to Kafka origin writes records directly to
            Kafka. <span class="ph">The origin does not pass records to its output port, so you
                        cannot perform additional processing or write the data to other destination
                        systems.</span></p>

        <p class="p">However, since a pipeline requires a destination, you should
                  connect the origin to the Trash destination to satisfy pipeline validation
                  requirements.</p>

        <p class="p">A pipeline with the UDP to Kafka origin should look like this:</p>

        <img class="image" id="concept_flq_twg_qw__image_z34_gdh_qw" src="../Graphics/UDPKafka-Pipeline.png" height="133" width="331" />
    </div>

</div>
<div class="topic concept nested1" id="concept_owg_1hc_rw">
 <h2 class="title topictitle2">Additional Kafka Properties</h2>

 <div class="body conbody">
  <p class="p">You can add custom Kafka configuration
            properties to the UDP to Kafka origin.</p>

        <p class="p">When you add a Kafka configuration property, enter the exact property name and
            the value. The stage does not validate the property names or values.</p>

        <p class="p">Several properties are defined by default, you can edit or remove the properties
            as necessary.</p>

        <div class="note note"><span class="notetitle">Note:</span> Because the stage uses several configuration properties, it ignores
                user-defined values for the following properties:<ul class="ul" id="concept_owg_1hc_rw__d77924e36">
                    <li class="li">key.serializer.class</li>

                    <li class="li">metadata.broker.list</li>

                    <li class="li">partitioner.class</li>

                    <li class="li">producer.type</li>

                    <li class="li">serializer.class</li>

                </ul>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_kn3_tjc_rw">
 <h2 class="title topictitle2">Enabling Kafka Security</h2>

 <div class="body conbody">
        <p class="p">You can configure the UDP to Kafka origin to
            connect securely to Kafka through SSL/TLS, Kerberos, or both. </p>

 </div>

<div class="topic concept nested2" id="concept_wb5_sxc_rw">
 <h3 class="title topictitle3">Enabling SSL/TLS</h3>

 <div class="body conbody">
        <p class="p">Perform the following steps to enable the UDP to Kafka
            origin to use SSL/TLS to connect to Kafka. </p>

        <div class="p">
            <ol class="ol" id="concept_wb5_sxc_rw__d58886e25">
                <li class="li" id="concept_wb5_sxc_rw__d58886e27">To use SSL/TLS to connect, first make sure Kafka is
                    configured for SSL/TLS as described in the <a class="xref" href="http://kafka.apache.org/documentation.html#security_ssl" target="_blank">Kafka documentation</a>. </li>

                <li class="li" id="concept_wb5_sxc_rw__d58886e33">On the <span class="ph uicontrol">General</span> tab of the stage, set
                    the <span class="ph uicontrol">Stage Library</span> property to the appropriate Apache
                    Kafka version.</li>

                <li class="li" id="concept_wb5_sxc_rw__d58886e42">On the <strong class="ph b">Kafka</strong> tab, add the <strong class="ph b">security.protocol</strong> Kafka configuration
                    property and set it to <strong class="ph b">SSL</strong>.</li>

                <li class="li" id="concept_wb5_sxc_rw__d58886e54">Then add and configure the following SSL Kafka
                        properties:<ul class="ul" id="concept_wb5_sxc_rw__d58886e56">
                        <li class="li">ssl.truststore.location</li>

                        <li class="li">ssl.truststore.password</li>

                    </ul>
<div class="p">When the Kafka broker requires client authentication - when the
                        ssl.client.auth broker property is set to "required" - add and configure the
                        following properties: <ul class="ul" id="concept_wb5_sxc_rw__d58886e66">
                            <li class="li">ssl.keystore.location</li>

                            <li class="li">ssl.keystore.password</li>

                            <li class="li">ssl.key.password</li>

                        </ul>
</div>
<div class="p">Some brokers might require adding the following properties as
                            well:<ul class="ul" id="concept_wb5_sxc_rw__d58886e79">
                            <li class="li">ssl.enabled.protocols</li>

                            <li class="li">ssl.truststore.type</li>

                            <li class="li">ssl.keystore.type</li>

                        </ul>
</div>
<p class="p">For details about these properties, see the Kafka
                        documentation.</p>
</li>

            </ol>

        </div>

        <p class="p">For example, the following properties allow the stage to use SSL/TLS to
            connect to Kafka with client authentication:</p>

        <img class="image" id="concept_wb5_sxc_rw__image_hgt_xzc_rw" src="../../../reusable-content/datacollector/reusable-topics/../../../datacollector/UserGuide/Graphics/Kafka-SSLoptions.png" height="179" width="549" />
    </div>

</div>
<div class="topic concept nested2" id="concept_xyx_mtd_rw">
    <h3 class="title topictitle3">Enabling Kerberos (SASL)</h3>

 <div class="body conbody">
        <p class="p">When you
            use Kerberos authentication, <span class="ph">Data Collector</span>
            uses the Kerberos principal and keytab to connect to Kafka. Perform the following steps
            to enable the UDP to Kafka origin to use Kerberos to connect to Kafka.</p>

        <div class="p">
            <ol class="ol">
                <li class="li" id="concept_xyx_mtd_rw__d58940e39">To use Kerberos, first make sure Kafka is configured for
                    Kerberos as described in the <a class="xref" href="http://kafka.apache.org/documentation.html#security_sasl" target="_blank">Kafka documentation</a>.</li>

                <li class="li" id="concept_xyx_mtd_rw__d58940e45">Make sure that Kerberos authentication is enabled for <span class="ph">Data Collector</span>, as described
                    in <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</li>

                <li class="li" id="concept_xyx_mtd_rw__d58940e52">Add the Java Authentication and Authorization
                    Service (JAAS) configuration properties required for Kafka clients based on your
                    installation and authentication type:<ul class="ul" id="concept_xyx_mtd_rw__d58940e54">
                        <li class="li"><span class="ph uicontrol">RPM, tarball, or Cloudera Manager installation without LDAP
                                authentication</span> - If <span class="ph">Data Collector</span> does
                            not use LDAP authentication, create a separate JAAS configuration file
                            on the <span class="ph">Data Collector</span>
                            machine. Add the following <samp class="ph codeph">KafkaClient</samp> login section to
                            the
                                file:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</pre>
</div>
<div class="p">Then
                                modify the SDC_JAVA_OPTS environment variable to include the
                                following option that defines the path to the JAAS configuration
                                file:<pre class="pre codeblock">-Djava.security.auth.login.config=&lt;JAAS config path&gt;</pre>
</div>
<p class="p"><a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_zhl_rb3_qcb">Modify environment variables</a> using the method required by your installation
                  type.</p>
</li>

                        <li class="li"><span class="ph uicontrol">RPM or tarball installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in an
                            RPM or tarball installation, add the properties to the JAAS
                            configuration file used by <span class="ph">Data Collector</span> - the
                                <samp class="ph codeph">$SDC_CONF/ldap-login.conf</samp> file. Add the following
                                <samp class="ph codeph">KafkaClient</samp> login section to the end of the
                                <samp class="ph codeph">ldap-login.conf</samp>
                                file:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</pre>
</div>
</li>

                        <li class="li"><span class="ph uicontrol">Cloudera Manager installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in a
                            Cloudera Manager installation, enable the LDAP Config File Substitutions
                            (ldap.login.file.allow.substitutions) property for the StreamSets
                            service in Cloudera Manager.<p class="p">If the Use Safety Valve to Edit LDAP
                                Information (use.ldap.login.file) property is enabled and LDAP
                                authentication is configured in the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for ldap-login.conf field, then
                                add the JAAS configuration properties to the same ldap-login.conf
                                safety valve.</p>
<p class="p">If LDAP authentication is configured through the
                                LDAP properties rather than the ldap-login.conf safety value, add
                                the JAAS configuration properties to the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for
                                generated-ldap-login-append.conf field.</p>
<p class="p">Add the following
                                    <samp class="ph codeph">KafkaClient</samp> login section to the appropriate
                                field as
                                follows:</p>
<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="&lt;principal name&gt;/_HOST@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="sdc/_HOST@EXAMPLE.COM";
};</pre>
</div>
<p class="p">Cloudera
                                Manager generates the appropriate keytab path and host name.
                            </p>
</li>

                    </ul>
</li>

                <li class="li">On the <span class="keyword wintitle">General</span> tab of the stage, set the <span class="ph uicontrol">Stage
                        Library</span> property to the appropriate Apache Kafka version.</li>

                <li class="li" id="concept_xyx_mtd_rw__d58940e135">On the <span class="keyword wintitle">Kafka</span> tab, add the
                        <span class="ph uicontrol">security.protocol</span> Kafka configuration property, and
                    set it to <span class="ph uicontrol">SASL_PLAINTEXT</span>.</li>

                <li class="li" id="concept_xyx_mtd_rw__d58940e148">Then, add the
                        <span class="ph uicontrol">sasl.kerberos.service.name</span> configuration property,
                    and set it to <span class="ph uicontrol">kafka</span>. </li>

            </ol>

        </div>

        <p class="p">For example, the following Kafka properties enable connecting to Kafka
            with Kerberos:</p>

        <p class="p"><img class="image" id="concept_xyx_mtd_rw__d58940e163" src="../../../reusable-content/datacollector/reusable-topics/../../../datacollector/UserGuide/Graphics/Kafka-Kerberos.png" height="95" width="639" /></p>

    </div>

</div>
<div class="topic concept nested2" id="concept_xgk_4yd_rw">
 <h3 class="title topictitle3">Enabling SSL/TLS and Kerberos</h3>

 <div class="body conbody">
  <p class="p">You can
            enable the UDP to Kafka origin to use SSL/TLS and Kerberos to connect to Kafka.</p>

        <div class="p"><span class="ph" id="concept_xgk_4yd_rw__d59115e28">To use SSL/TLS and Kerberos, combine the required
                steps to enable each and set the security.protocol property as follows:</span>
            <ol class="ol" id="concept_xgk_4yd_rw__d59115e31">
                <li class="li" id="concept_xgk_4yd_rw__d59115e33">Make sure Kafka is configured to use SSL/TLS and
                    Kerberos (SASL) as described in the following Kafka documentation:<ul class="ul" id="concept_xgk_4yd_rw__d59115e35">
                        <li class="li"><a class="xref" href="http://kafka.apache.org/documentation.html#security_ssl" target="_blank">http://kafka.apache.org/documentation.html#security_ssl</a></li>

                        <li class="li"><a class="xref" href="http://kafka.apache.org/documentation.html#security_sasl" target="_blank">http://kafka.apache.org/documentation.html#security_sasl</a></li>

                    </ul>
</li>

                <li class="li">Make sure that Kerberos authentication is enabled for <span class="ph">Data Collector</span>, as described
                    in <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</li>

                <li class="li">Add the Java Authentication and Authorization
                    Service (JAAS) configuration properties required for Kafka clients based on your
                    installation and authentication type:<ul class="ul" id="concept_xgk_4yd_rw__d58940e54">
                        <li class="li"><span class="ph uicontrol">RPM, tarball, or Cloudera Manager installation without LDAP
                                authentication</span> - If <span class="ph">Data Collector</span> does
                            not use LDAP authentication, create a separate JAAS configuration file
                            on the <span class="ph">Data Collector</span>
                            machine. Add the following <samp class="ph codeph">KafkaClient</samp> login section to
                            the
                                file:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</pre>
</div>
<div class="p">Then
                                modify the SDC_JAVA_OPTS environment variable to include the
                                following option that defines the path to the JAAS configuration
                                file:<pre class="pre codeblock">-Djava.security.auth.login.config=&lt;JAAS config path&gt;</pre>
</div>
<p class="p"><a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_zhl_rb3_qcb">Modify environment variables</a> using the method required by your installation
                  type.</p>
</li>

                        <li class="li"><span class="ph uicontrol">RPM or tarball installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in an
                            RPM or tarball installation, add the properties to the JAAS
                            configuration file used by <span class="ph">Data Collector</span> - the
                                <samp class="ph codeph">$SDC_CONF/ldap-login.conf</samp> file. Add the following
                                <samp class="ph codeph">KafkaClient</samp> login section to the end of the
                                <samp class="ph codeph">ldap-login.conf</samp>
                                file:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</pre>
</div>
</li>

                        <li class="li"><span class="ph uicontrol">Cloudera Manager installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in a
                            Cloudera Manager installation, enable the LDAP Config File Substitutions
                            (ldap.login.file.allow.substitutions) property for the StreamSets
                            service in Cloudera Manager.<p class="p">If the Use Safety Valve to Edit LDAP
                                Information (use.ldap.login.file) property is enabled and LDAP
                                authentication is configured in the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for ldap-login.conf field, then
                                add the JAAS configuration properties to the same ldap-login.conf
                                safety valve.</p>
<p class="p">If LDAP authentication is configured through the
                                LDAP properties rather than the ldap-login.conf safety value, add
                                the JAAS configuration properties to the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for
                                generated-ldap-login-append.conf field.</p>
<p class="p">Add the following
                                    <samp class="ph codeph">KafkaClient</samp> login section to the appropriate
                                field as
                                follows:</p>
<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="&lt;principal name&gt;/_HOST@&lt;realm&gt;";
};</pre>
<div class="p">For
                                example:<pre class="pre codeblock">KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="sdc/_HOST@EXAMPLE.COM";
};</pre>
</div>
<p class="p">Cloudera
                                Manager generates the appropriate keytab path and host name.
                            </p>
</li>

                    </ul>
</li>

                <li class="li">On the <span class="keyword wintitle">General</span> tab of the stage, set the <span class="ph uicontrol">Stage
                        Library</span> property to the appropriate Apache Kafka version.</li>

                <li class="li" id="concept_xgk_4yd_rw__d59115e57">On the <span class="keyword wintitle">Kafka</span> tab, add the
                        <span class="ph uicontrol">security.protocol</span> property and set it to
                        <span class="ph uicontrol">SASL_SSL</span>.</li>

                <li class="li">Then, add the
                        <span class="ph uicontrol">sasl.kerberos.service.name</span> configuration property,
                    and set it to <span class="ph uicontrol">kafka</span>. </li>

                <li class="li">Then add and configure the following SSL Kafka
                        properties:<ul class="ul" id="concept_xgk_4yd_rw__d58886e56">
                        <li class="li">ssl.truststore.location</li>

                        <li class="li">ssl.truststore.password</li>

                    </ul>
<div class="p">When the Kafka broker requires client authentication - when the
                        ssl.client.auth broker property is set to "required" - add and configure the
                        following properties: <ul class="ul" id="concept_xgk_4yd_rw__d58886e66">
                            <li class="li">ssl.keystore.location</li>

                            <li class="li">ssl.keystore.password</li>

                            <li class="li">ssl.key.password</li>

                        </ul>
</div>
<div class="p">Some brokers might require adding the following properties as
                            well:<ul class="ul" id="concept_xgk_4yd_rw__d58886e79">
                            <li class="li">ssl.enabled.protocols</li>

                            <li class="li">ssl.truststore.type</li>

                            <li class="li">ssl.keystore.type</li>

                        </ul>
</div>
<p class="p">For details about these properties, see the Kafka
                        documentation.</p>
</li>

            </ol>
</div>

 </div>

</div>
</div>
<div class="topic task nested1" id="task_tvh_bhz_pw">
    <h2 class="title topictitle2">Configuring a UDP to Kafka Origin</h2>

    <div class="body taskbody">
        <div class="section context">
            <p class="p">Configure
                a UDP to Kafka origin to process UDP messages and write them directly to Kafka. </p>

        </div>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_tvh_bhz_pw__d47645e613" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d422652e717">General Property</th>

                                    <th class="entry" valign="top" width="70%" id="d422652e720">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e717 ">Name</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e720 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e717 ">Description</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e720 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e717 ">Stage Library</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e720 ">Library version that you want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e717 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">
                                            <img class="image" id="task_tvh_bhz_pw__d47645e668" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e720 ">Error record handling for the stage: <ul class="ul" id="task_tvh_bhz_pw__d47645e672">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">UDP</span> tab, configure the following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_tvh_bhz_pw__table_h4d_33z_pw" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d422652e805">UDP Property</th>

                                    <th class="entry" valign="top" width="70%" id="d422652e808">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e805 ">Port</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e808 ">Port to listen to for data. Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the<span class="ph uicontrol">
                                            Add</span> icon to list additional ports.<div class="note note"><span class="notetitle">Note:</span> To
                                            listen to a port below 1024, <span class="ph">Data Collector</span> must be run by a user with root privileges.
                                            Otherwise, the operating system does not allow <span class="ph">Data Collector</span> to bind to the port.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e805 ">Data Format</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e808 ">Data format passed by UDP:<ul class="ul" id="task_tvh_bhz_pw__ul_xnb_xzc_vbb">
                                            <li class="li">collectd</li>

                                            <li class="li">NetFlow</li>

                                            <li class="li">syslog</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Kafka</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_tvh_bhz_pw__table_khc_klz_pw" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d422652e886">UDP Property</th>

                                    <th class="entry" valign="top" width="70%" id="d422652e889">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e886 ">Broker URI</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e889 ">Connection string for the Kafka broker. Use the following
                                        format: <samp class="ph codeph">&lt;host&gt;:&lt;port&gt;</samp>. <p class="p">To ensure a
                                            connection, enter a comma-separated list of additional
                                            broker URIs.</p>
</td>

                                </tr>
 <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e886 ">Topic</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e889 ">Kafka topic to read.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e886 ">Kafka Configuration <a class="xref" href="UDPtoKafka.html#concept_owg_1hc_rw">
                                        <img class="image" id="task_tvh_bhz_pw__image_mwv_b52_zq" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a>
                                    </td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e889 ">
                                        <p class="p">Additional Kafka configuration
                                            properties to use. Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                                <span class="ph uicontrol">Add</span> icon to add properties.
                                            Define the Kafka property name and value.</p>

                                        <p class="p">Use the property names and values as
                                            expected by Kafka.</p>

                                        <p class="p">For information about enabling secure connections to
                                            Kafka, see <a class="xref" href="UDPtoKafka.html#concept_kn3_tjc_rw">Enabling Kafka Security</a>.</p>

                                    </td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Advanced</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_tvh_bhz_pw__table_zny_pmz_pw" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d422652e980">Advanced Property</th>

                                    <th class="entry" valign="top" width="70%" id="d422652e983">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e980 ">Enable UDP Multithreading</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e983 ">Specifies whether to use
                                        multiple receiver threads for each port. Using multiple
                                        receiver threads can improve performance. <p class="p">You can use
                                            multiple receiver threads using epoll, which can be
                                            available when <span class="ph">Data Collector</span> runs on recent versions of 64-bit Linux. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e980 ">Accept Threads</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e983 "><span class="ph" id="task_tvh_bhz_pw__d47645e4904">Number of receiver
                                            threads to use for each port. For example, if you
                                            configure two threads per port and configure the origin
                                            to use three ports, the origin uses a total of six
                                            threads.</span><p class="p" id="task_tvh_bhz_pw__d47645e4906">Use to
                                            increase the number of threads passing data to the
                                            origin when epoll is available on the <span class="ph">Data Collector</span> machine.</p>
<p class="p">Default is 1.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e980 ">Write Concurrency</td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e983 ">Maximum number of Kafka clients that the origin can use
                                        to write to Kafka. <p class="p">When configuring this property,
                                            consider the number of Kafka brokers, partitions, and
                                            volume of data to be written.</p>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For NetFlow 9 data, on the <span class="ph uicontrol">NetFlow 9</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info" id="task_tvh_bhz_pw__d47645e5087">When processing earlier versions of NetFlow data, these
                    properties are ignored. 
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_tvh_bhz_pw__d47645e5089" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d422652e1059">Netflow 9 Property</th>

                                    <th class="entry" valign="top" width="70%" id="d422652e1062">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e1059 "><span class="ph" id="task_tvh_bhz_pw__d47645e5114">Record Generation Mode <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_jdh_hxk_3bb">
                                                <img class="image" id="task_tvh_bhz_pw__d47645e5118" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></span></td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e1062 "><span class="ph" id="task_tvh_bhz_pw__d47645e5121">Determines the type of
                                            values to include in the record. Select one of the
                                            following options:</span><ul class="ul" id="task_tvh_bhz_pw__d47645e5123">
                                            <li class="li">Raw Only</li>

                                            <li class="li">Interpreted Only</li>

                                            <li class="li">Both Raw and Interpreted</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e1059 "><span class="ph" id="task_tvh_bhz_pw__d47645e5139">Max Templates in
                                            Cache</span></td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e1062 "><span class="ph" id="task_tvh_bhz_pw__d47645e5143">The maximum number of
                                            templates to store in the template cache. For more
                                            information about templates, see <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_ivr_j1l_3bb">Caching NetFlow 9 Templates</a>.</span><p class="p"><span class="ph" id="task_tvh_bhz_pw__d47645e5148">Default is -1
                                                for an unlimited cache size.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d422652e1059 "><span class="ph" id="task_tvh_bhz_pw__d47645e5155">Template Cache
                                            Timeout (ms)</span></td>

                                    <td class="entry" valign="top" width="70%" headers="d422652e1062 "><span class="ph" id="task_tvh_bhz_pw__d47645e5159">The maximum number
                                            of milliseconds to cache an idle template. Templates
                                            unused for more than the specified time are evicted from
                                            the cache. For more information about templates, see
                                                <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_ivr_j1l_3bb">Caching NetFlow 9 Templates</a>.</span><p class="p"><span class="ph" id="task_tvh_bhz_pw__d47645e5164">Default is -1 for caching templates
                                                indefinitely.</span></p>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>
</div>
            </li>
</ol>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../../../datacollector/UserGuide/Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>