
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />        
      <meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Einstein Analytics" /><meta name="abstract" content="The Einstein Analytics destination writes data to Salesforce Einstein Analytics. The destination connects to Einstein Analytics to upload external data to a dataset." /><meta name="description" content="The Einstein Analytics destination writes data to Salesforce Einstein Analytics. The destination connects to Einstein Analytics to upload external data to a dataset." /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Destinations/Destinations-title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_hlx_r53_rx" /><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/css/commonltr.css?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></link><title>Einstein Analytics</title><!--  Generated with Oxygen version @@WEBHELP_VERSION@@, build number @@WEBHELP_BUILD_NUMBER@@.  --><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/css/webhelp_topic.css?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></link><link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/resources/skins/skin.css?buildId=@@WEBHELP_BUILD_NUMBER@@" /><script type="text/javascript"><!--
          
          var prefix = "../../../index.html";
          
          --></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery-3.1.1.min.js"><!----></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../../../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../../../oxygen-webhelp/resources/js/log.js?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></script><script type="text/javascript" charset="utf-8" src="../../../oxygen-webhelp/resources/js/webhelp_topic.js?buildId=@@WEBHELP_BUILD_NUMBER@@"><!----></script>
  <!--
  Copyright 2018 StreamSets Inc.
  
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
  <script type="text/javascript">
    <!--
    var parentWindow = window.name;
    console.log("1. " + parentWindow);
    if (!(parentWindow == "frm" || parentWindow == "contentwin")) {
        var currHash = window.location.hash.substr(1);
        console.log("2. " + currHash);
        console.log("3. " + currHash.indexOf("datacollector/UserGuide/"));

        if ( currHash.indexOf("datacollector/UserGuide/") == -1 ) {
            window.location.hash = "#datacollector/UserGuide/" + currHash;
        }
    }
-->
  </script>
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../../../datacollector/UserGuide/Destinations/Destinations-title.html" title="Destinations">Destinations</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../../../datacollector/UserGuide/Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_hlx_r53_rx">
    <h1 class="title topictitle1">Einstein Analytics</h1>

    
    <div class="body conbody"><p class="shortdesc">The Einstein Analytics destination writes data to Salesforce Einstein Analytics. The
        destination connects to Einstein Analytics to upload external data to a dataset.</p>

        <p class="p">When
            you configure the destination, you define connection information, including the API
            version that the destination uses to connect to Einstein Analytics. </p>

        <p class="p">You specify the <em class="ph i">edgemart alias</em> or name of the dataset to upload data to. You can
            also optionally define the name of the edgemart container or app that contains the
            dataset. </p>

        <p class="p">The destination can upload external data to a new dataset or to an existing dataset using
            an append, delete, overwrite, or upsert operation. Based on the operation type, you
            define the metadata of the data to be uploaded in JSON format.</p>

        <p class="p">You can optionally use an HTTP proxy to connect to Salesforce Einstein Analytics. When
            enabled in Salesforce, you can configure the destination to use mutual authentication to
            connect to Salesforce.</p>

    </div>

<div class="related-links"></div>
<div class="topic task nested1" id="task_kff_4vn_jz">
    <h2 class="title topictitle2">Changing the API Version</h2>

    <div class="body taskbody">
        <div class="section context">
            <p class="p"><span class="ph">Data Collector</span> ships with version <span class="ph">39.0</span> of the Salesforce Web Services Connector libraries. You can use a different
                Salesforce API version if you need to access functionality not present in version
                    <span class="ph">39.0</span>.</p>

        </div>

        <ol class="ol steps" id="task_kff_4vn_jz__steps_imt_zck_dy"><li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Salesforce</span> tab, set the <span class="ph uicontrol">API
                        Version</span> property to the version that you want to use, for
                    example 36.0.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Download the relevant version of the following JAR files from Salesforce Web
                    Services Connector (WSC):</span>
                <ul class="ul choices" id="task_kff_4vn_jz__d33467e48">
                    <li class="li choice">
                        <p class="p">WSC JAR file - force-wsc-&lt;version&gt;.0.0.jar </p>

                    </li>

                    <li class="li choice">
                        <p class="p">Partner API JAR file - force-partner-api-&lt;version&gt;.0.0.jar</p>

                    </li>

                </ul>

                <div class="itemgroup info">
                    <p class="p">Where &lt;version&gt; is the API version number, for example, 36.</p>
 
                    <p class="p">For information about downloading libraries from Salesforce WSC, see <a class="xref" href="https://developer.salesforce.com/page/Introduction_to_the_Force.com_Web_Services_Connector" target="_blank">https://developer.salesforce.com/page/Introduction_to_the_Force.com_Web_Services_Connector</a>.</p>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the following <span class="ph">Data Collector</span> directory,
                    replace the default force-wsc-39.0.0.jar and force-partner-api-39.0.0.jar files
                    with the versioned JAR files that you downloaded:</span>
                <div class="itemgroup info">
                    <pre class="pre codeblock">$SDC_DIST/streamsets-libs/streamsets-datacollector-salesforce-lib/lib/</pre>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Restart <span class="ph">Data Collector</span>
                    for the changes to take effect.</span>
            </li>
</ol>

    </div>

</div>
<div class="topic concept nested1" id="concept_ryp_g4r_vcb">
    <h2 class="title topictitle2">Define the Operation</h2>

    <div class="body conbody">
        <div class="p">Configure the Einstein Analytics destination to
            perform one of the following operations when it uploads external data to a dataset:<ul class="ul" id="concept_ryp_g4r_vcb__ul_zh1_fkt_vcb">
                <li class="li">Append - Appends data to the dataset, creating the dataset if it doesn’t
                    exist.</li>

                <li class="li">Delete - Deletes rows from the dataset. The rows to delete must contain a single
                    field with a unique identifier.</li>

                <li class="li">Overwrite - Replaces data in the dataset, creating the dataset if it doesn't
                    exist.</li>

                <li class="li">Upsert - Inserts or updates rows in the dataset, creating the dataset if it
                    doesn’t exist. The rows to upsert must contain a single field with a unique
                    identifier.</li>

            </ul>
</div>

        <p class="p">For more information about unique identifiers, see the <a class="xref" href="https://developer.salesforce.com/docs/atlas.en-us.bi_dev_guide_ext_data_format.meta/bi_dev_guide_ext_data_format/bi_ext_data_schema_reference.htm" target="_blank">Salesforce Developer documentation</a>. </p>

    </div>

<div class="topic concept nested2" id="concept_qln_pct_vcb">
    <h3 class="title topictitle3">Metadata JSON</h3>

    <div class="body conbody">
        <div class="p">Uploading external data to an Einstein
            Analytics dataset involves using the following files:<ul class="ul" id="concept_qln_pct_vcb__ul_ebs_wft_vcb">
                <li class="li">Data file that contains the external data.</li>

                <li class="li">Optional metadata file that describes the schema of the data in JSON
                    format.</li>

            </ul>
</div>

        <p class="p">The Einstein Analytics destination creates the data file based on the incoming record.
            You define the metadata in JSON format when you configure the destination.</p>

        <p class="p">You must define metadata for the append, upsert, and delete operations. For append and
            upsert, the metadata must match the metadata of the dataset being uploaded to. For
            delete, the metadata must be a subset of the dataset columns.</p>

        <p class="p">You can optionally define metadata for the overwrite operation so that Einstein Analytics
            can correctly interpret the data type of the data. If you do not enter metadata, then
            Einstein Analytics treats every field as text. </p>

        <p class="p">For more information about how Einstein Analytics handles JSON metadata for uploaded
            external data, see the <a class="xref" href="https://developer.salesforce.com/docs/atlas.en-us.bi_dev_guide_ext_data_format.meta/bi_dev_guide_ext_data_format/bi_ext_data_schema_overview.htm" target="_blank">Salesforce Developer documentation</a>.</p>

    </div>

</div>
</div>
<div class="topic concept nested1" id="concept_d4h_2lj_tx">
 <h2 class="title topictitle2">Dataflow (Deprecated)</h2>

 
 <div class="body conbody"><p class="shortdesc">In previous releases, you could configure the destination to use an Einstein Analytics
        dataflow to combine multiple datasets together. However, using dataflows is now deprecated
        and will be removed in a future release. We recommend configuring the destination to use the
        append operation to combine data into a single dataset.</p>

        <p class="p">An Einstein Analytics dataflow
            includes instructions and transformations to combine datasets. Create the dataflow in
            Einstein Analytics. Then when you configure the Einstein Analytics destination, specify
            the name of the existing dataflow. The dataflow should not contain any content, as the
            Einstein Analytics destination overwrites any existing content.</p>

        <p class="p">By default, a dataflow runs every 24 hours. However, you can configure the dataflow to
            run each time the destination closes and uploads a dataset to Einstein Analytics. In
            Einstein Analytics, you can run a dataflow a maximum of 24 times in a 24 hour period. So
            if you choose to run the dataflow after each dataset upload, make sure that the
            configured dataset wait time is more than an hour. </p>

        <p class="p">For more information about creating dataflows, see the Salesforce Einstein Analytics
            documentation.</p>

    </div>

</div>
<div class="topic task nested1" id="task_mdt_dv3_rx">
    <h2 class="title topictitle2">Configuring an Einstein Analytics Destination</h2>

    <div class="body taskbody">
        <div class="section context">Configure an Einstein
            Analytics destination to write data to Salesforce Einstein Analytics.</div>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_mdt_dv3_rx__d18242e5695" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d177744e319">General Property</th>

                                    <th class="entry" valign="top" width="70%" id="d177744e322">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d177744e319 ">Name</td>

                                    <td class="entry" valign="top" width="70%" headers="d177744e322 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d177744e319 ">Description</td>

                                    <td class="entry" valign="top" width="70%" headers="d177744e322 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d177744e319 ">Required Fields <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq">
                                            <img class="image" id="task_mdt_dv3_rx__d18242e5741" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d177744e322 ">Fields that must include data for the record to be passed
                                        into the stage. <div class="note tip"><span class="tiptitle">Tip:</span> You might
                                            include fields that the stage uses.</div>
<p class="p">Records
                                            that do not include all required fields are processed
                                            based on the error handling configured for the
                                            pipeline.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d177744e319 ">Preconditions <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs">
                                            <img class="image" id="task_mdt_dv3_rx__d18242e5757" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d177744e322 ">Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <span class="ph uicontrol">Add</span> to create additional
                                        preconditions. <p class="p">Records that do not meet all preconditions
                                            are processed based on the error handling configured for
                                            the stage.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d177744e319 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">
                                            <img class="image" id="task_mdt_dv3_rx__d18242e5774" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d177744e322 ">Error record handling for the stage: <ul class="ul" id="task_mdt_dv3_rx__d18242e5778">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Analytics</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_mdt_dv3_rx__table_qyk_lmj_tx" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="33.33333333333333%" id="d177744e433">Analytics Property</th>

                                    <th class="entry" valign="top" width="66.66666666666666%" id="d177744e436">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Username</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Salesforce username in the following email format:
        <samp class="ph codeph">&lt;text&gt;@&lt;text&gt;.com</samp>. </td>

     </tr>

                                <tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Password</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Salesforce password.<p class="p">If the machine running <span class="ph">Data Collector</span> is outside the trusted IP range
        configured in your Salesforce environment, you must generate a security token and then set
        this property to the password followed by the security token. </p>
<p class="p">For example, if the
        password is abcd and the security token is 1234, then set this property to abcd1234. For
        more information on generating a security token, see <a class="xref" href="https://help.salesforce.com/articleView?id=user_security_token.htm&amp;type=0" target="_blank">Reset Your Security Token</a>.</p>

       <div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph" id="task_mdt_dv3_rx__d18309e4741">To
                        secure sensitive information such as usernames and passwords, you can use
                              <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></span></div>
</td>

     </tr>

                                <tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Auth Endpoint</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Salesforce SOAP API authentication endpoint. Enter one of the following values:<ul class="ul" id="task_mdt_dv3_rx__d18372e3611">
        <li class="li">login.salesforce.com - Use to connect to a Production or Developer Edition
         organization.</li>

        <li class="li">test.salesforce.com - Use to connect to a sandbox organization.</li>

       </ul>
<p class="p">Default is login.salesforce.com.</p>
</td>

     </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">API Version <a class="xref" href="WaveAnalytics.html#task_kff_4vn_jz">
                                            <img class="image" id="task_mdt_dv3_rx__image_weh_nch_er" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Salesforce API version to use to connect to Salesforce.
        <p class="p">Default is <span class="ph">39.0</span>. If you change the version, you also must download the relevant JAR files from Salesforce
        Web Services Connector (WSC).</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Edgemart Alias</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Dataset name. The alias must be unique across an
                                        organization. </td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Append Timestamp to Alias</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Appends the edgemart alias or dataset name with the
                                        timestamp of the dataset upload.<p class="p">To create a new dataset
                                            for each upload of data, select this option. To append,
                                            delete, overwrite, or upsert data to an existing
                                            dataset, clear this option. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Edgemart Container</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Name of the edgemart container or app that contains the
                                        dataset. Enter the developer name or the ID of the app
                                        rather than the display label.<p class="p">For example, the developer
                                            name of an app is "AnalyticsCloudPublicDatasets", but
                                            the display label of the app is "Analytics Cloud Public
                                            Datasets".</p>
<p class="p">To get the developer name or ID, run
                                            the following query in Salesforce: </p>
<div class="p">
                                            <pre class="pre codeblock">SELECT Id,DeveloperName,Name, AccessType,CreatedDate,Type FROM Folder where Type = 'Insights' </pre>

                                        </div>
<p class="p">If not defined when the destination creates a new
                                            dataset, the destination uses the user's private app. If
                                            not defined when the destination uploads to an existing
                                            dataset, Einstein Analytics resolves the app name.
                                            </p>
<p class="p">If defined when the destination uploads to an
                                            existing dataset, the name must match the name of the
                                            current app containing the existing dataset.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Operation <a class="xref" href="WaveAnalytics.html#concept_ryp_g4r_vcb">
                                            <img class="image" id="task_mdt_dv3_rx__image_egh_jcz_mr" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Operation to perform when uploading external data to a
                                        dataset.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Dataset Wait Time (secs)</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Maximum time in seconds to wait for new data to arrive.
                                        After no data has arrived in this amount of time, the
                                        destination uploads the data to Einstein Analytics.<p class="p">The
                                            dataset wait time must be at least as long as the Batch
                                            Wait Time for the origin in the pipeline.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Use Dataflow <a class="xref" href="WaveAnalytics.html#concept_d4h_2lj_tx" title="In previous releases, you could configure the destination to use an Einstein Analytics dataflow to combine multiple datasets together. However, using dataflows is now deprecated and will be removed in a future release. We recommend configuring the destination to use the append operation to combine data into a single dataset.">
                                            <img class="image" id="task_mdt_dv3_rx__image_wjh_ycl_br" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Determines whether to use an Einstein Analytics dataflow
                                        to combine multiple datasets together. <div class="note important"><span class="importanttitle">Important:</span> Using dataflows is now deprecated and
                                            will be removed in a future release. We recommend
                                            configuring the destination to use the append operation
                                            to combine data into a single dataset.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Dataflow Name</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Name of the existing dataflow. <p class="p">You must create the
                                            dataflow in Einstein Analytics. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Run Dataflow After Upload</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Determines whether the destination runs the dataflow each
                                        time that it uploads a dataset to Einstein
                                        Analytics.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e433 ">Metadata JSON <a class="xref" href="WaveAnalytics.html#concept_qln_pct_vcb">
                                            <img class="image" id="task_mdt_dv3_rx__image_djk_ykh_br" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e436 ">Metadata in JSON format that describes the schema of the
                                        data to be uploaded.<p class="p">Required for the append, upsert, and
                                            delete operations. Optional for the overwrite
                                            operation.</p>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Advanced</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_mdt_dv3_rx__table_qgc_5l2_kz" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="33.33333333333333%" id="d177744e683">Advanced Property</th>

                                    <th class="entry" valign="top" width="66.66666666666666%" id="d177744e686">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Use Proxy</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Specifies whether to use an HTTP proxy to connect to Salesforce.</td>

     </tr>
<tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Proxy Hostname</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Proxy host.</td>

     </tr>
<tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Proxy Port</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Proxy port.</td>

     </tr>
<tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Proxy Requires Credentials</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Specifies whether the proxy requires a user name and password.</td>

     </tr>
<tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Proxy Username</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">User name for proxy credentials.</td>

     </tr>
<tr>
      <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Proxy Password</td>

      <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Password for proxy credentials.<div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph" id="task_mdt_dv3_rx__d18309e4741">To
                        secure sensitive information such as usernames and passwords, you can use
                              <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></span></div>
</td>

     </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Use Mutual Authentication</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">When enabled in Salesforce, you can use SSL/TLS mutual
                                        authentication to connect to Salesforce. <p class="p">Mutual
                                            authentication is not enabled in Salesforce by default.
                                            To enable mutual authentication, contact Salesforce.
                                            </p>
<p class="p">Before enabling mutual authentication, you must
                                            store a <a class="xref" href="https://help.salesforce.com/articleView?id=security_keys_uploading_mutual_auth_cert.htm&amp;type=0" target="_blank">mutual authentication
                                                certificate</a> in the Data Collector resources
                                            directory. For more information, see <a class="xref" href="../Pipeline_Configuration/SSL-TLS.html#concept_kqb_rqf_5z">Keystore and Truststore Configuration</a>.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Keystore File <a class="xref" href="../Pipeline_Configuration/SSL-TLS.html#concept_kqb_rqf_5z">
                                            <img class="image" id="task_mdt_dv3_rx__d18242e3363" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">The path to the keystore file. Enter an absolute path to
                                        the file or a path relative to the <span class="ph">Data Collector</span> resources directory: <span class="ph filepath">$SDC_RESOURCES</span>.
                                                <p class="p"><span class="ph">For more information about environment variables, see
                              <a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr" title="Data Collector includes environment variables that define the directories used to store configuration, data, log, and resource files.When you run Data Collector as a service, Data Collector runs as the system user account and group defined in environment variables. The default system user and group are named sdc.Increase or decrease the Data Collector Java heap size as necessary, based on the resources available on the host machine. By default, the Java heap size is 1024 MB. You can enable remote debugging to debug a Data Collector instance running on a remote machine. You can define the Java garbage collector that Data Collector uses. By default, Data Collector uses the Concurrent Mark Sweep (CMS) garbage collector.Data Collector includes a Java Security Manager that is enabled by default. You can edit the SDC_ROOT_CLASSPATH environment variable to define the path to JAR files to be added to the Data Collector root classloader.">Data Collector Environment Configuration</a>.</span></p>
<p class="p">By default, no keystore is used. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Keystore Type</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Type of keystore to use. Use one of the following
                                            types:<ul class="ul" id="task_mdt_dv3_rx__d18242e3385">
                                            <li class="li">Java Keystore File (JKS)</li>

                                            <li class="li">PKCS-12 (p12 file)</li>

                                        </ul>
<p class="p">Default is Java Keystore File (JKS). </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Keystore Password</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">Password to the keystore file. A password is optional,
                                        but recommended.<div class="p">
                                            <div class="note tip"><span class="tiptitle">Tip:</span> To secure sensitive information such as
                  passwords, you can use <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></div>

                                        </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="33.33333333333333%" headers="d177744e683 ">Keystore Key Algorithm</td>

                                    <td class="entry" valign="top" width="66.66666666666666%" headers="d177744e686 ">The algorithm used to manage the keystore. <p class="p">Default is
                                                <span class="ph">SunX509</span>.</p>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
</ol>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../../../datacollector/UserGuide/Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>